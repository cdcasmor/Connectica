{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectica Multi-Vendor Invoicing Program\n",
    "This notebook showcases how the invoicing process of data engineering and normalization works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import sys\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompting user with task choice\n",
    "decision = str(input(\"Please make selection from the menu below\\n(1)Unzip\\n(2)Thinq Outbound\\n(3)Avoxi\\n(4)Didx\\n(5)Migesa\\n(6)ThinQ Inbound\\n(Q)Quit\\nChoice: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip Extraction\n",
    "The following blocks of code look for files that correspond to the date selected accross the different Thinq directories of our NAS (USA, International or Inbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if decision == \"1\":\n",
    "    date_selection = input('Enter a year and month in format YYYY-MM: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    path = 'Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR'\n",
    "    file_list = os.listdir(path)\n",
    "    file_list = [word for word in file_list if word.startswith(date_selection)]\n",
    "    intl_counter = 0\n",
    "    inbound_counter = 0\n",
    "    usa_counter = 0\n",
    "        for file in file_list:\n",
    "        if file[11:15] == 'intl':\n",
    "            file_path = 'Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\' + file\n",
    "            with ZipFile(file_path, 'r') as zipObj:\n",
    "            # Extract all the contents of zip file in different directory\n",
    "                zipObj.extractall('Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\Extract\\\\International')\n",
    "                intl_counter += 1\n",
    "        elif file[11:15] == 'orig':\n",
    "            file_path = 'Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\' + file\n",
    "            with ZipFile(file_path, 'r') as zipObj:\n",
    "            # Extract all the contents of zip file in different directory\n",
    "                zipObj.extractall('Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\Extract\\\\Inbound')\n",
    "                inbound_counter += 1\n",
    "        else:\n",
    "            file_path = 'Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\' + file\n",
    "            with ZipFile(file_path, 'r') as zipObj:\n",
    "            # Extract all the contents of zip file in different directory\n",
    "                zipObj.extractall('Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\Extract\\\\USA')\n",
    "                usa_counter += 1\n",
    "          \n",
    "    print(' International files have been extracted')\n",
    "    print(' Inbound files have been extracted')\n",
    "    print(' USA files have been extracted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinq Inbound CDR\n",
    "Merging and normalizing data from files extracted using the unzip functionality above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if decision == \"2\":\n",
    "    prompt = input('Enter USA or International with the first letter capitalized: ')\n",
    "    date_selection = input('Enter a year and month in format YYYY-MM: ')\n",
    "    path = 'Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\Extract\\\\' + prompt\n",
    "    file_list = os.listdir(path)\n",
    "    file_list = [word for word in file_list if word.startswith(date_selection)]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting a single CDR made from all cdr's shown above, \n",
    "# dataframe normalized and exported to csv\n",
    "thinq_dataframes = []\n",
    "for file in file_list:\n",
    "    filename = \"../../Nico/Vendors/Thinq/CDR/Extract/\" + prompt + \"/\" + file\n",
    "    thinq_dataframes.append(pd.read_csv(filename))\n",
    "    thinq_df = pd.concat(thinq_dataframes)\n",
    "\n",
    "for index, row in thinq_df.iterrows():\n",
    "    thinq_df['Disposition'] = 'ANSWERED'\n",
    "    thinq_df['CallerID'] = thinq_df['from_ani']\n",
    "thinq_df = thinq_df.reindex_axis(['time','from_ani','to_did','billsec','CallerID','Disposition','total','src_ip'], axis=1)\n",
    "thinq_df = thinq_df.rename(index=str, columns={\"time\": \"Date\", \"from_ani\": \"Source\",\"to_did\": \"Destination\",\"billsec\": \"Seconds\",\"total\": \"Cost\",\"src_ip\": \"Peer\"})\n",
    "\n",
    "if prompt == \"USA\":\n",
    "    thinq_df.to_csv('thinq_cdr_dom.csv', encoding='utf-8' , index=False, header=False)\n",
    "    print(\"The output cdr was saved as thinq_cdr_dom.csv\\n\")\n",
    "else:\n",
    "    thinq_df.to_csv('thinq_cdr_int.csv', encoding='utf-8' , index=False, header=False)\n",
    "    print(\"The output cdr was saved as thinq_cdr_int.csv\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoxi CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elif decision == \"3\":\n",
    "    #Importing avoxi file:\n",
    "    avoxi_name = input('Enter the name of the avoxi file: ')\n",
    "    file = \"Avoxi/\" + avoxi_name\n",
    "    avoxi_raw = pd.read_csv(file)\n",
    "\n",
    "    for index, row in avoxi_raw.iterrows():\n",
    "        avoxi_raw['Disposition'] = 'ANSWERED'\n",
    "        avoxi_raw['CallerID'] = ''\n",
    "\n",
    "    avoxi_raw = avoxi_raw[['Date/Time','From','To','Duration', 'CallerID', 'Disposition', 'Cost', 'Number/Ext./SIP Trunk']]\n",
    "    avoxi_df = avoxi_raw.rename(index=str, columns={\"Date/Time\": \"Date\", \"From\": \"Source\",\"To\": \"Destination\",\"Duration\": \"Seconds\",\"Number/Ext./SIP Trunk\": \"Peer\"})\n",
    "\n",
    "    avoxi_df = avoxi_df.sort_values(by='Date', ascending=True) # This now sorts in date order\n",
    "\n",
    "    avoxi_df.to_csv('avoxi_cdr.csv', encoding='utf-8' , index=False, header=False)\n",
    "    print(\"The output cdr was saved as avoxi_cdr.csv\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIDX CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif decision == \"4\":\n",
    "    #Importing didx file:\n",
    "    didx_name = input('Enter the name of the didx file: ')\n",
    "    file = \"DIDX/\" + didx_name\n",
    "    didx_raw = pd.read_csv(file)\n",
    "\n",
    "    didx_raw['Peer'] = didx_raw['Destination']\n",
    "\n",
    "    didx_raw = didx_raw[['CallDate','CallFrom','Destination','Duration (sec)', 'CallID', 'Status', 'TotalCost', 'Peer']]\n",
    "    didx_df = didx_raw.rename(index=str, columns={\"CallDate\": \"Date\", \"CallFrom\": \"Source\",\"Duration (sec)\": \"Seconds\",\"CallID\": \"CallerID\",\"Status\": \"Disposition\",\"TotalCost\": \"Cost\"})\n",
    "    didx_df = didx_df.sort_values(by='Date', ascending=True) # This now sorts in date order\n",
    "    \n",
    "    #Date format fix\n",
    "    j = 0\n",
    "    i = 0\n",
    "    dimension = (len(didx_df['Date']) - 1)\n",
    "    Date = []\n",
    "    while (i <= dimension):\n",
    "        Date.append(str(didx_df['Date'][i]))\n",
    "        i += 1\n",
    "\n",
    "    newdates =[]\n",
    "    for date in Date:\n",
    "        d = datetime.datetime.strptime(date, '%d-%m-%Y %H:%M')\n",
    "        date = d.strftime('%Y-%m-%d %H:%M:00')\n",
    "        newdates.append(date)\n",
    "\n",
    "    didx_df['Date'] = newdates\n",
    "    #Disposition column fix\t\n",
    "    for index, row in didx_df.iterrows():\n",
    "        didx_df['CallerID'] = \"\"\n",
    "    for answer in didx_df['Disposition']:\n",
    "        if didx_df['Disposition'][j] == \"ANSWER\":\n",
    "            didx_df['Disposition'][j] = \"ANSWERED\"\n",
    "            j += 1\n",
    "        elif didx_df['Disposition'][j] == \"CANCEL\":\n",
    "            didx_df['Disposition'][j] = \"NO ANSWER\"\n",
    "            j += 1\n",
    "        elif didx_df['Disposition'][j] == \"BUSY\":\n",
    "            didx_df['Disposition'][j] = \"BUSY\"\n",
    "            j += 1\n",
    "        else: \n",
    "            print(\"There is an unknown value on the disposition column\")\n",
    "            j += 1\n",
    "\n",
    "    didx_df.to_csv('didx_cdr.csv', encoding='utf-8' , index=False,header=False)\n",
    "    print(\"The output cdr was saved as didx_cdr.csv\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migesa CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elif decision == \"5\":\n",
    "    #migesa\n",
    "    migesa_name = input('Enter the name of the migesa file: ')\n",
    "    migesa_raw = pd.read_csv(migesa_name)\n",
    "    \n",
    "    for index, row in migesa_raw.iterrows():\n",
    "        migesa_raw['Cost'] = migesa_raw['duration']*(.087/60)\n",
    "        migesa_raw['Peer'] = \"38.100.65.27\"\n",
    "\n",
    "    migesa_raw = migesa_raw[['calldate','src','dst','duration', 'clid', 'disposition', 'Cost', 'Peer']]\n",
    "    migesa_df = migesa_raw.rename(index=str, columns={\"calldate\": \"Date\", \"src\": \"Source\",\"dst\": \"Destination\",\"duration\": \"Seconds\",\"clid\": \"CallerID\", \"disposition\": \"Disposition\"})\n",
    "        migesa_df.to_csv('migesa_cdr.csv', encoding='utf-8', index=False, header=False)\n",
    "\n",
    "    print(\"The output cdr was saved as migesa_cdr.csv\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinq Outbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elif decision == \"6\":\n",
    "    date_selection = input('Enter a year and month in format YYYY-MM: ')\n",
    "    path = 'Z:\\\\Sync\\\\Nico\\\\Vendors\\\\ThinQ\\\\CDR\\\\Extract\\\\Inbound\\\\'\n",
    "    file_list = os.listdir(path)\n",
    "    file_list = [word for word in file_list if word.startswith(date_selection)]\n",
    "    thinq_dataframes = []\n",
    "    for file in file_list:\n",
    "        filename = \"../../Nico/Vendors/Thinq/CDR/Extract/Inbound/\" + file\n",
    "        thinq_dataframes.append(pd.read_csv(filename))\n",
    "        thinq_df = pd.concat(thinq_dataframes)\n",
    "    for index, row in thinq_df.iterrows():\n",
    "        thinq_df['Disposition'] = 'ANSWERED'\n",
    "        thinq_df['CallerID'] = thinq_df['from_ani']\n",
    "        thinq_df['Date'] = thinq_df['date'] + \" \" + thinq_df['time']\t\t\n",
    "        thinq_df = thinq_df.reindex_axis(['Date','from_ani','to_did','billsec','CallerID','Disposition','total_charge','dest'], axis=1)\n",
    "        thinq_df = thinq_df.rename(index=str, columns={\"from_ani\": \"Source\",\"to_did\": \"Destination\",\"billsec\": \"Seconds\",\"total_charge\": \"Cost\",\"dest\": \"Peer\"})\n",
    "        \n",
    "        thinq_df.to_csv('thinq_cdr_inbound.csv', encoding='utf-8' , index=False, header=False)\n",
    "        print(\"The output cdr was saved as thinq_cdr_inbound.csv\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
